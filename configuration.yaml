# General Configuration
model:
  name: "gazemoe_dinov2_vitl14_inout"  # "gazelle_dinov2_vitl14_inout" OR "gazemoe_dinov2_vitl14_inout"
  pretrained_path: "pretrainShared_epoch_14.pt"  #"pretrainShared_epoch_14.pt" or "gazelle_dinov2_vitl14_inout.pt"
  mlp_ratio: 4  # hidden_dim = ( ) * in_feats, ratio between FFN dim and input feature size 4->2
  num_experts: 4  # Routed experts 8->4
  num_shared_experts: 1  # Shared experts 2->1
  top_k: 2  # 2 / 1
  moe_type: "shared"  # vanilla / shared / else (moe)
  is_msf: 1
  is_focal_loss: 1  # if using FocalLoss for class balancing
  pbce_loss: "bce"  #"mse" or "bce" or "hybrid"
  reduction: "mean"  #"mean" or "none"
  bce_weight: 1.0  # 0.1 for ChildPlay
  mse_weight: 180.0
  angle_weight: 0.0  # 0.05 / 0.1
  vec_weight: 0.0
  kld_weight: 0.01  # 0.01, 0.02, 0.05, 0.1
  encoder:
    type: "DINOv2"                  # Pretrained image encoder (DINOv2, CLIP, etc.)
    pretrained: true                # Use pretrained weights
  decoder:
    hidden_size: 256                # d_model
    depth: 3                        # Number of transformer layers in the decoder (default 3)
    num_heads: 8                    # Number of attention heads
    dropout: 0.1                    # Dropout rate

data:
  input_resolution: 448
  train_path: "./VAT"     # Path to preprocessed training dataset
  test_path: "./VAT"       # Path to preprocessed test dataset
  pre_train_path: "./gazefollow_extended"
  pre_test_path: "./gazefollow_extended"
  augmentations: []

train:
  # VAT finetuning hyperparams
  batch_size: 36                    # Batch size for training
  epochs: 10                    # Number of training epochs
  lr: 0.0001                         # 0.00001 for VAt; 0.0001 for ChildPlay
  inout_lr: 0.0002
  fuse_lr: 0.0001
  block_lr: 0.0001
  layer_decay: 0                    # 0 or 1
  optimizer: "Adam"                # Optimizer type (adam, adamw, sgd, etc.)
  weight_decay: 0.01                # Weight decay for optimizer
  lr_scheduler:                     # Learning rate scheduler settings
    type: "cosine"                  # cosine / linear / warmup (for warmup training)
    step_size: 15                   # Step size for step scheduler / warmup: warmup_epochs
    gamma: 0.1                      # Decay factor for step/exponential scheduler
    min_lr: 1e-7                    # Minimum learning rate for cosine/other schedulers
  gradient_clipping: 5.0            # Gradient clipping threshold
  # GazeFollow pretrain hyperparams
  pre_lr: 0.001
  pre_fuse_lr: 0.001
  pre_block_lr: 0.001
  pre_batch_size: 60   # 60
  pre_epochs: 15   # 15
  pre_optimizer: "Adam"
  pre_lr_scheduler:
    type: "cosine"                  # cosine / linear
    step_size: 15                   # Step size for step scheduler
    gamma: 0.1                      # Decay factor for step/exponential scheduler
    min_lr: 1e-7                    # Minimum learning rate for cosine/other schedulers

eval:
  checkpoint: ""                    # Path to the checkpoint for Eval
  batch_size: 36                    # Batch size for evaluation

inference:
  checkpoint: ""

logging:
  log_dir: "results/ChildPlay_shared_focal/"           # auto naming
  pre_dir: "results/pretrainShared/"
  save_every: 5

hardware:
  device: "cuda:2"                    # Device to use (cuda, cpu)
  num_workers: 3                    # Number of data loader workers
  pin_memory: True                  # Pin memory for faster data loading
